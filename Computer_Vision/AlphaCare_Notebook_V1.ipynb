{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trying-missile",
   "metadata": {},
   "source": [
    "## Step 1 - Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Keras + Tensorflow for Deep Learning (Convolutional Neural Network)\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, AvgPool1D, Flatten, Dense, Dropout, Softmax\n",
    "from keras.optimizers import Adam \n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import regularizers\n",
    "\n",
    "##PYWT for Wavelet transformation (denoising)\n",
    "import pywt\n",
    "\n",
    "##Scikit-learn for model stats & data splitting\n",
    "from scipy import stats\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "##Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##OS level helper tools for data reading\n",
    "import csv\n",
    "import itertools\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import collections\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-runner",
   "metadata": {},
   "source": [
    "## Step 2 - Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's set some parameters for our visualization\n",
    "plt.rcParams['lines.color'] = 'b'\n",
    "plt.rcParams['axes.grid'] = True \n",
    "plt.rcParams[\"figure.figsize\"] = (30,6)\n",
    "plt.rcParams['lines.linewidth'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the denoising function\n",
    "def denoise(data): \n",
    "    w = pywt.Wavelet('sym4')\n",
    "    maxlev = pywt.dwt_max_level(len(data), w.dec_len)\n",
    "    threshold = 0.04 \n",
    "\n",
    "    coeffs = pywt.wavedec(data, 'sym4', level=maxlev)\n",
    "    for i in range(1, len(coeffs)):\n",
    "        coeffs[i] = pywt.threshold(coeffs[i], threshold*max(coeffs[i]))\n",
    "        \n",
    "    datarec = pywt.waverec(coeffs, 'sym4')\n",
    "    \n",
    "    return datarec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Retrieve the data!\n",
    "path = './input/mitbih_database/'\n",
    "window_size = 180\n",
    "maximum_counting = 10000\n",
    "\n",
    "classes = ['N', 'L', 'R', 'A', 'V']\n",
    "n_classes = len(classes)\n",
    "count_classes = [0]*n_classes\n",
    "\n",
    "X = list()\n",
    "y = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "filenames = next(os.walk(path))[2]\n",
    "\n",
    "# Split and save .csv , .txt \n",
    "records = list()\n",
    "annotations = list()\n",
    "filenames.sort()\n",
    "\n",
    "# separate filenames and annotations\n",
    "for f in filenames:\n",
    "    filename, file_extension = os.path.splitext(f)\n",
    "    \n",
    "    # *.csv\n",
    "    if(file_extension == '.csv'):\n",
    "        records.append(path + filename + file_extension)\n",
    "\n",
    "    # *.txt\n",
    "    else:\n",
    "        annotations.append(path + filename + file_extension)\n",
    "\n",
    "# Create DataRecords\n",
    "for r in range(0,len(records)):\n",
    "    signals = []\n",
    "\n",
    "    with open(records[r], 'rt') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|') # read CSV file\\\n",
    "        row_index = -1\n",
    "        for row in spamreader:\n",
    "            if(row_index >= 0):\n",
    "                signals.insert(row_index, int(row[1]))\n",
    "            row_index += 1\n",
    "            \n",
    "    # Plot an example to the signals\n",
    "    if r is 1:\n",
    "        # Plot each patient's signal\n",
    "        plt.title(records[1] + \" Wave 1\")\n",
    "        plt.plot(signals[0:700])\n",
    "        plt.show()\n",
    "        \n",
    "    signals = denoise(signals)\n",
    "    # Plot an example to the signals\n",
    "    if r is 1:\n",
    "        # Plot each patient's signal\n",
    "        plt.title(records[1] + \" wave after denoised\")\n",
    "        plt.plot(signals[0:700])\n",
    "        plt.show()\n",
    "        \n",
    "    signals = stats.zscore(signals)\n",
    "    # Plot an example to the signals\n",
    "    if r is 1:\n",
    "        # Plot each patient's signal\n",
    "        plt.title(records[1] + \" wave after z-score normalization \")\n",
    "        plt.plot(signals[0:700])\n",
    "        plt.show()\n",
    "    \n",
    "    # Read anotations: R position and Arrhythmia class\n",
    "    example_beat_printed = False\n",
    "    with open(annotations[r], 'r') as fileID:\n",
    "        data = fileID.readlines() \n",
    "        beat = list()\n",
    "\n",
    "        for d in range(1, len(data)): # 0 index is Chart Head\n",
    "            splitted = data[d].split(' ')\n",
    "            splitted = filter(None, splitted)\n",
    "            next(splitted) # Time... Clipping\n",
    "            pos = int(next(splitted)) # Sample ID\n",
    "            arrhythmia_type = next(splitted) # Type\n",
    "            if(arrhythmia_type in classes):\n",
    "                arrhythmia_index = classes.index(arrhythmia_type)\n",
    "#                 if count_classes[arrhythmia_index] > maximum_counting: # avoid overfitting\n",
    "#                     pass\n",
    "#                 else:\n",
    "                count_classes[arrhythmia_index] += 1\n",
    "                if(window_size <= pos and pos < (len(signals) - window_size)):\n",
    "                    beat = signals[pos-window_size:pos+window_size]     \n",
    "                    # Plot an example to a beat    \n",
    "                    if r is 1 and not example_beat_printed: \n",
    "                        plt.title(\"A Beat from \" + records[1] + \" Wave\")\n",
    "                        plt.plot(beat)\n",
    "                        plt.show()\n",
    "                        example_beat_printed = True\n",
    "\n",
    "                    X.append(beat)\n",
    "                    y.append(arrhythmia_index)\n",
    "\n",
    "# data shape\n",
    "print(np.shape(X), np.shape(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(X)):\n",
    "        X[i] = np.append(X[i], y[i])\n",
    "\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X)\n",
    "per_class = X_train_df[X_train_df.shape[1]-1].value_counts()\n",
    "print(per_class)\n",
    "plt.figure(figsize=(20,10))\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "plt.pie(per_class, labels=['N', 'L', 'R', 'A', 'V'], colors=['tab:blue','tab:orange','tab:purple','tab:olive','tab:green'],autopct='%1.1f%%')\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-yugoslavia",
   "metadata": {},
   "source": [
    "## Step 3 - Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=X_train_df[X_train_df[X_train_df.shape[1]-1]==1]\n",
    "df_2=X_train_df[X_train_df[X_train_df.shape[1]-1]==2]\n",
    "df_3=X_train_df[X_train_df[X_train_df.shape[1]-1]==3]\n",
    "df_4=X_train_df[X_train_df[X_train_df.shape[1]-1]==4]\n",
    "df_0=(X_train_df[X_train_df[X_train_df.shape[1]-1]==0]).sample(n=5000,random_state=42)\n",
    "\n",
    "df_1_upsample=resample(df_1,replace=True,n_samples=5000,random_state=122)\n",
    "df_2_upsample=resample(df_2,replace=True,n_samples=5000,random_state=123)\n",
    "df_3_upsample=resample(df_3,replace=True,n_samples=5000,random_state=124)\n",
    "df_4_upsample=resample(df_4,replace=True,n_samples=5000,random_state=125)\n",
    "\n",
    "X_train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])\n",
    "\n",
    "per_class = X_train_df[X_train_df.shape[1]-1].value_counts()\n",
    "print(per_class)\n",
    "plt.figure(figsize=(20,10))\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "plt.pie(per_class, labels=['N', 'L', 'R', 'A', 'V'], colors=['tab:blue','tab:orange','tab:purple','tab:olive','tab:green'],autopct='%1.1f%%')\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(X_train_df, test_size=0.20)\n",
    "\n",
    "print(\"X_train : \", np.shape(train))\n",
    "print(\"X_test  : \", np.shape(test))\n",
    "\n",
    "target_train=train[train.shape[1]-1]\n",
    "target_test=test[test.shape[1]-1]\n",
    "train_y=to_categorical(target_train)\n",
    "test_y=to_categorical(target_test)\n",
    "print(np.shape(train_y), np.shape(test_y))\n",
    "\n",
    "train_x = train.iloc[:,:train.shape[1]-1].values\n",
    "test_x = test.iloc[:,:test.shape[1]-1].values\n",
    "train_x = train_x.reshape(len(train_x), train_x.shape[1],1)\n",
    "test_x = test_x.reshape(len(test_x), test_x.shape[1],1)\n",
    "print(np.shape(train_x), np.shape(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-surgery",
   "metadata": {},
   "source": [
    "## Step 4 - Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CNN \n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=16, kernel_size=13, padding='same', activation='relu',input_shape=(360, 1)))\n",
    "model.add(AvgPool1D(pool_size=3, strides=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=15, padding='same', activation='relu'))\n",
    "model.add(AvgPool1D(pool_size=3, strides=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=17, padding='same', activation='relu'))\n",
    "model.add(AvgPool1D(pool_size=3, strides=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=19, padding='same', activation='relu'))\n",
    "model.add(AvgPool1D(pool_size=3, strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(35,kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dense(5,kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Softmax())\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-rubber",
   "metadata": {},
   "source": [
    "## Step 5 - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(train_x, train_y, batch_size=36, epochs=60, verbose=1, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-wireless",
   "metadata": {},
   "source": [
    "## Step 6 - Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
